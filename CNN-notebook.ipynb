{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "Currently, one of the most common (and accurate) methods for conducting a Blood\n",
    "Smear is manually. The goal of this project is to develop a neural network that can classify WBCs from images as part of an eventual effort to automate the procedure without a significant loss in accuracy. By automating this process, we can not only speed it up, but we also reduce the amount of human labor required to conduct a test, thus lowering the overall cost.\n",
    "\n",
    "The dataset for this project is a collection of ~12,500 images that are 240 x 320. The images contain several RBCs and a single, highlighted WBC. Each WBC falls into one of four categories: Eosinophil, Lymphocyte, Monocyte, or Neutrophil. The dataset can be found on Kaggle [here](https://www.kaggle.com/paultimothymooney/blood-cells). Through accurate classification, accurate proportions of each WBC type could be calculated and checked for normalcy. Additionally, cell images could be further inspected for abnormalities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "import warnings  \n",
    "with warnings.catch_warnings():  \n",
    "    warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "    import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.optimizers import Adadelta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration\n",
    "\n",
    "Let's begin by taking a look at an example of each of the four types of WBC we'll be attempting to classify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                 | 0/2497 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EOSINOPHIL Training Image Files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2497/2497 [00:40<00:00, 61.44it/s]\n",
      "  1%|▎                                         | 5/623 [00:00<00:13, 46.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading EOSINOPHIL Testing Image Files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 623/623 [00:11<00:00, 55.73it/s]\n",
      "  0%|                                         | 6/2499 [00:00<00:43, 56.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NEUTROPHIL Training Image Files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2499/2499 [00:34<00:00, 71.43it/s]\n",
      "  1%|▍                                         | 7/624 [00:00<00:09, 63.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading NEUTROPHIL Testing Image Files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 624/624 [00:09<00:00, 65.85it/s]\n",
      "  0%|                                         | 6/2483 [00:00<00:49, 49.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LYMPHOCYTE Training Image Files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2483/2483 [00:36<00:00, 67.59it/s]\n",
      "  1%|▍                                         | 7/620 [00:00<00:10, 60.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LYMPHOCYTE Testing Image Files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 620/620 [00:11<00:00, 54.34it/s]\n",
      "  0%|                                         | 7/2478 [00:00<00:35, 69.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MONOCYTE Training Image Files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 2478/2478 [00:41<00:00, 60.33it/s]\n",
      "  1%|▎                                         | 4/620 [00:00<00:20, 29.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading MONOCYTE Testing Image Files\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████| 620/620 [00:14<00:00, 42.44it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 720x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wbc_types = ['EOSINOPHIL', 'NEUTROPHIL', 'LYMPHOCYTE', 'MONOCYTE']\n",
    "wbc_df = pd.DataFrame(columns=['file_name', 'type', 'group'])\n",
    "X_train = []\n",
    "X_test = []\n",
    "y_train = []\n",
    "y_test = []\n",
    "\n",
    "plt.figure(figsize=(10,8))\n",
    "\n",
    "for i, wbc_type in enumerate(wbc_types):\n",
    "    path = 'dataset2-master/images/TRAIN/' + wbc_type + '/'\n",
    "    files = os.listdir(path)\n",
    "    print(\"Loading {} Training Image Files\".format(wbc_type))\n",
    "    for file in tqdm(files):\n",
    "        image = load_img(path + file)\n",
    "        image = image.resize((150,150))\n",
    "        new_row = {'file_name': file,\n",
    "                   'type': wbc_type, \n",
    "                   'group': 'train'}\n",
    "        wbc_df = wbc_df.append(new_row, ignore_index=True)\n",
    "        X_train.append(np.asarray(image))\n",
    "        y_train.append(i)\n",
    "    path2 = 'dataset2-master/images/TEST/' + wbc_type + '/'\n",
    "    files2 = os.listdir(path2)\n",
    "    print(\"Loading {} Testing Image Files\".format(wbc_type))\n",
    "    for file2 in tqdm(files2):\n",
    "        image = load_img(path2 + file2)\n",
    "        image = image.resize((150,150))\n",
    "        new_row = {'file_name': file2,\n",
    "                   'type': wbc_type,\n",
    "                   'group': 'test'}\n",
    "        wbc_df = wbc_df.append(new_row, ignore_index=True)\n",
    "        X_test.append(np.asarray(image))\n",
    "        y_test.append(i)\n",
    "    \n",
    "#     df = pd.DataFrame(columns=['file_name', 'type'])\n",
    "#     df['file_name'] = files\n",
    "#     df.fillna(value=wbc_type, inplace=True)\n",
    "#     wbc_df = wbc_df.append(df)\n",
    "    \n",
    "#     image = load_img(path + files[0])\n",
    "#     plt.subplot(2,2,i+1)\n",
    "#     plt.title(wbc_type)\n",
    "#     plt.axis('off')\n",
    "#     plt.imshow(image)\n",
    "    \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.countplot(x='group', hue='type', data=wbc_df)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.asarray(X_train)\n",
    "X_train = X_train/255.0\n",
    "\n",
    "y_train = np.asarray(y_train)\n",
    "y_train = to_categorical(y_train, num_classes=4)\n",
    "\n",
    "X_test = np.asarray(X_test)\n",
    "X_test = X_test/255.0\n",
    "\n",
    "y_test = np.asarray(y_test)\n",
    "y_test = to_categorical(y_test, num_classes=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The images show that each of the four cell types are quite easily visually differentiable. Additionally, we can see from the countplot that our training data is very well balanced with ~2,500 images of each WBC cell type."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction\n",
    "\n",
    "Since the input to be classified are image files, we will be using a Convolutional Neural Network for these purposes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Andrew\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    }
   ],
   "source": [
    "batch_size = 128\n",
    "image_height = 150\n",
    "image_width = 150\n",
    "\n",
    "# model accuracy reached 0.3155 after 1.5 hours and 30 epochs\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(image_height,image_width,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "#model.add(Dropout(0.5))\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "optimizer = Adadelta()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizer,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n",
    "        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False)  # randomly flip images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "311/311 [==============================] - 180s 580ms/step - loss: 1.3885 - acc: 0.2489 - val_loss: 1.3880 - val_acc: 0.2477\n",
      "Epoch 2/30\n",
      "311/311 [==============================] - 174s 559ms/step - loss: 1.3875 - acc: 0.2507 - val_loss: 1.3877 - val_acc: 0.2465\n",
      "Epoch 3/30\n",
      "311/311 [==============================] - 174s 559ms/step - loss: 1.3870 - acc: 0.2546 - val_loss: 1.3852 - val_acc: 0.2694\n",
      "Epoch 4/30\n",
      "311/311 [==============================] - 184s 590ms/step - loss: 1.3856 - acc: 0.2628 - val_loss: 1.3861 - val_acc: 0.2682\n",
      "Epoch 5/30\n",
      "311/311 [==============================] - 182s 585ms/step - loss: 1.3854 - acc: 0.2634 - val_loss: 1.3834 - val_acc: 0.2778\n",
      "Epoch 6/30\n",
      "311/311 [==============================] - 184s 593ms/step - loss: 1.3846 - acc: 0.2672 - val_loss: 1.3823 - val_acc: 0.2537\n",
      "Epoch 7/30\n",
      "311/311 [==============================] - 185s 595ms/step - loss: 1.3843 - acc: 0.2714 - val_loss: 1.3821 - val_acc: 0.2730\n",
      "Epoch 8/30\n",
      "311/311 [==============================] - 184s 591ms/step - loss: 1.3833 - acc: 0.2720 - val_loss: 1.3804 - val_acc: 0.2766\n",
      "Epoch 9/30\n",
      "311/311 [==============================] - 184s 592ms/step - loss: 1.3827 - acc: 0.2720 - val_loss: 1.3794 - val_acc: 0.3112\n",
      "Epoch 10/30\n",
      "311/311 [==============================] - 179s 575ms/step - loss: 1.3826 - acc: 0.2756 - val_loss: 1.3787 - val_acc: 0.3494\n",
      "Epoch 11/30\n",
      "311/311 [==============================] - 178s 571ms/step - loss: 1.3819 - acc: 0.2826 - val_loss: 1.3781 - val_acc: 0.2984\n",
      "Epoch 12/30\n",
      "311/311 [==============================] - 176s 564ms/step - loss: 1.3809 - acc: 0.2797 - val_loss: 1.3771 - val_acc: 0.3237\n",
      "Epoch 13/30\n",
      "311/311 [==============================] - 178s 572ms/step - loss: 1.3803 - acc: 0.2894 - val_loss: 1.3761 - val_acc: 0.2887\n",
      "Epoch 14/30\n",
      "311/311 [==============================] - 178s 571ms/step - loss: 1.3788 - acc: 0.2958 - val_loss: 1.3758 - val_acc: 0.2811\n",
      "Epoch 15/30\n",
      "311/311 [==============================] - 176s 565ms/step - loss: 1.3785 - acc: 0.2916 - val_loss: 1.3745 - val_acc: 0.3116\n",
      "Epoch 16/30\n",
      "311/311 [==============================] - 179s 577ms/step - loss: 1.3782 - acc: 0.2990 - val_loss: 1.3738 - val_acc: 0.3257\n",
      "Epoch 17/30\n",
      "311/311 [==============================] - 184s 592ms/step - loss: 1.3767 - acc: 0.3056 - val_loss: 1.3729 - val_acc: 0.3325\n",
      "Epoch 18/30\n",
      "311/311 [==============================] - 183s 589ms/step - loss: 1.3757 - acc: 0.3052 - val_loss: 1.3699 - val_acc: 0.3695\n",
      "Epoch 19/30\n",
      "311/311 [==============================] - 183s 589ms/step - loss: 1.3749 - acc: 0.3086 - val_loss: 1.3692 - val_acc: 0.3241\n",
      "Epoch 20/30\n",
      "311/311 [==============================] - 179s 576ms/step - loss: 1.3738 - acc: 0.3075 - val_loss: 1.3690 - val_acc: 0.3052\n",
      "Epoch 21/30\n",
      "311/311 [==============================] - 178s 572ms/step - loss: 1.3734 - acc: 0.3100 - val_loss: 1.3681 - val_acc: 0.2947\n",
      "Epoch 22/30\n",
      "311/311 [==============================] - 183s 587ms/step - loss: 1.3721 - acc: 0.3138 - val_loss: 1.3651 - val_acc: 0.3116\n",
      "Epoch 23/30\n",
      "311/311 [==============================] - 180s 579ms/step - loss: 1.3717 - acc: 0.3158 - val_loss: 1.3634 - val_acc: 0.3398\n",
      "Epoch 24/30\n",
      "311/311 [==============================] - 182s 585ms/step - loss: 1.3705 - acc: 0.3163 - val_loss: 1.3623 - val_acc: 0.3261\n",
      "Epoch 25/30\n",
      "311/311 [==============================] - 181s 581ms/step - loss: 1.3699 - acc: 0.3301 - val_loss: 1.3603 - val_acc: 0.3844\n",
      "Epoch 26/30\n",
      "311/311 [==============================] - 180s 579ms/step - loss: 1.3682 - acc: 0.3333 - val_loss: 1.3617 - val_acc: 0.3438\n",
      "Epoch 27/30\n",
      "311/311 [==============================] - 179s 577ms/step - loss: 1.3677 - acc: 0.3262 - val_loss: 1.3599 - val_acc: 0.3623\n",
      "Epoch 28/30\n",
      "311/311 [==============================] - 177s 570ms/step - loss: 1.3663 - acc: 0.3277 - val_loss: 1.3593 - val_acc: 0.3398\n",
      "Epoch 29/30\n",
      "311/311 [==============================] - 178s 571ms/step - loss: 1.3653 - acc: 0.3247 - val_loss: 1.3563 - val_acc: 0.3052\n",
      "Epoch 30/30\n",
      "311/311 [==============================] - 178s 573ms/step - loss: 1.3637 - acc: 0.3368 - val_loss: 1.3503 - val_acc: 0.3928\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7584813708>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_datagen.flow(X_train, y_train, batch_size=32),\n",
    "          steps_per_epoch=len(X_train) // 32,\n",
    "          epochs=30,\n",
    "          validation_data=(X_test, y_test),\n",
    "          validation_steps=2487 // 32)\n",
    "#model.save_weights('first_try.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
